{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dushyant3615/AI_Voice_Chatbot/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip -q install torch transformers datasets pandas speechrecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuQeQYRMf6kr",
        "outputId": "1b218c0a-e88e-4df6-93ce-1af163a2467e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip -q install pydub"
      ],
      "metadata": {
        "id": "n1GBqZ9ntgrA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3klY8Q49YqS",
        "outputId": "19d48f0b-2ce5-4389-f90a-9fca656a3c75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('wandb_login')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JOQRTwBxZ-m0",
        "outputId": "3e3b4a33-94f9-4139-e381-e274ba1f9aa5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'89473432b2be8cead22eda17275063a514ec2e88'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate"
      ],
      "metadata": {
        "id": "hJ2UwX-mpcfU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from datasets import Dataset, ClassLabel # Removed load_metric from datasets\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from evaluate import load_metric # Import load_metric from evaluate\n",
        "\n",
        "# Set seed for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Load Clinc AI dataset\n",
        "def load_clinc_data(file_path):\n",
        "    print(f\"Loading Clinc AI data from: {file_path}\")\n",
        "    with open(file_path, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    queries = [item[0] for item in data]  # User query\n",
        "    intents = [item[1] for item in data]  # Intent\n",
        "    print(f\"Loaded {len(queries)} queries from Clinc AI dataset.\")\n",
        "    return pd.DataFrame({\"query\": queries, \"intent\": intents})\n",
        "\n",
        "clinc_data = load_clinc_data(\"/content/drive/MyDrive/AI_voice_chatbot/Clinc_AI_Dataset/train.json\")\n",
        "print(f\"Clinc AI data shape: {clinc_data.shape}\")\n",
        "\n",
        "# Load Mozilla Common Voice data (optional, not used for training here)\n",
        "def load_mozilla_data(csv_path, audio_folder):\n",
        "    print(f\"Loading Mozilla Common Voice data from CSV: {csv_path}\")\n",
        "    df = pd.read_csv(csv_path, sep=\"\\t\")  # TSV file\n",
        "    print(f\"Loaded {len(df)} entries from Mozilla Common Voice CSV.\")\n",
        "\n",
        "    sentences = df['sentence'].tolist()\n",
        "    audio_files = [os.path.join(audio_folder, row['path']) for _, row in df.iterrows()]\n",
        "\n",
        "    return pd.DataFrame({\"sentence\": sentences, \"audio_path\": audio_files})\n",
        "\n",
        "mozilla_data = load_mozilla_data(\n",
        "    \"/content/drive/MyDrive/AI_voice_chatbot/Mozilla_Common_Voice_Dataset/cv-corpus-20.0-delta-2024-12-06/en/validated.tsv\",\n",
        "    \"/content/drive/MyDrive/AI_voice_chatbot/Mozilla_Common_Voice_Dataset/cv-corpus-20.0-delta-2024-12-06/en/clips\"\n",
        ")\n",
        "print(f\"Mozilla Common Voice data shape before filtering: {mozilla_data.shape}\")\n",
        "\n",
        "# Audio to text transcription function (optional)\n",
        "def audio_to_text(audio_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    if not os.path.exists(audio_path):\n",
        "        print(f\"File not found: {audio_path}\")\n",
        "        return \"\"\n",
        "\n",
        "    if audio_path.endswith(\".mp3\"):\n",
        "        try:\n",
        "            audio = AudioSegment.from_mp3(audio_path)\n",
        "            wav_path = audio_path.replace(\".mp3\", \".wav\")\n",
        "            audio.export(wav_path, format=\"wav\")\n",
        "            audio_path = wav_path\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting {audio_path} to WAV: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    try:\n",
        "        with sr.AudioFile(audio_path) as source:\n",
        "            audio = recognizer.record(source)\n",
        "            return recognizer.recognize_google(audio)\n",
        "    except sr.UnknownValueError:\n",
        "        print(f\"Could not transcribe audio: {audio_path}\")\n",
        "        return \"\"\n",
        "    except sr.RequestError:\n",
        "        print(f\"API error for audio: {audio_path}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error for audio: {audio_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Filter missing audio files (optional)\n",
        "initial_mozilla_rows = mozilla_data.shape[0]\n",
        "mozilla_data = mozilla_data[mozilla_data[\"audio_path\"].apply(os.path.exists)].copy()\n",
        "print(f\"Mozilla Common Voice data shape after filtering missing audio files: {mozilla_data.shape} ({initial_mozilla_rows - mozilla_data.shape[0]} rows filtered)\")\n",
        "\n",
        "# Transcribe audio (optional, can be slow)\n",
        "# print(\"Starting audio transcription for Mozilla Common Voice dataset...\")\n",
        "# mozilla_data[\"transcribed_text\"] = mozilla_data[\"audio_path\"].apply(audio_to_text)\n",
        "# print(\"Audio transcription complete.\")\n",
        "\n",
        "# Prepare labeled intent dataset (Clinc AI)\n",
        "print(\"Preparing labeled intent dataset (Clinc AI)...\")\n",
        "intent_data = clinc_data.rename(columns={\"query\": \"text\", \"intent\": \"label\"}).copy()\n",
        "\n",
        "# Build label mapping\n",
        "label_to_id = {label: idx for idx, label in enumerate(sorted(intent_data[\"label\"].unique()))}\n",
        "id_to_label = {v: k for k, v in label_to_id.items()}\n",
        "\n",
        "# Map labels to integers\n",
        "intent_data[\"label\"] = intent_data[\"label\"].map(label_to_id)\n",
        "\n",
        "# Force label dtype to int64\n",
        "intent_data[\"label\"] = intent_data[\"label\"].astype(\"int64\")\n",
        "\n",
        "print(f\"Number of unique intents: {len(label_to_id)}\")\n",
        "\n",
        "# Split dataset into train and validation sets\n",
        "train_df, val_df = train_test_split(intent_data, test_size=0.1, stratify=intent_data[\"label\"], random_state=42)\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "# Remove default index column if present\n",
        "for ds in [train_dataset, val_dataset]:\n",
        "    if \"__index_level_0__\" in ds.column_names:\n",
        "        ds = ds.remove_columns(\"__index_level_0__\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch tensors\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# Load pre-trained BERT model for sequence classification\n",
        "print(f\"Loading pre-trained BERT model (bert-base-uncased) with {len(label_to_id)} labels...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=len(label_to_id),\n",
        ")\n",
        "\n",
        "# Define compute metrics function for evaluation\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    save_total_limit=2,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Starting model training (only Clinc dataset)...\")\n",
        "trainer.train()\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Save model and tokenizer\n",
        "model.save_pretrained(\"trained_chatbot_model\")\n",
        "tokenizer.save_pretrained(\"trained_chatbot_model\")\n",
        "\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "sWHCFloalYgr",
        "outputId": "873d95f7-af32-4939-de35-56f5086859ae"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'load_metric' from 'evaluate' (/usr/local/lib/python3.12/dist-packages/evaluate/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1121653853.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_metric\u001b[0m \u001b[0;31m# Import load_metric from evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Set seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_metric' from 'evaluate' (/usr/local/lib/python3.12/dist-packages/evaluate/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d5ce9a1",
        "outputId": "22176eee-180f-479c-81ff-5446ed2f8577"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "loaded_model = AutoModelForSequenceClassification.from_pretrained(\"trained_chatbot_model\")\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(\"trained_chatbot_model\")\n",
        "print(\"Saved model and tokenizer loaded successfully.\")\n",
        "\n",
        "# Recreate the id_to_label mapping (assuming label_to_id was created during training)\n",
        "# If label_to_id is not available, you might need to load it from a saved file or re-create it\n",
        "# based on the unique labels in your training data.\n",
        "# For this example, we'll assume label_to_id is available from the previous training cell execution.\n",
        "# If you are running this cell independently, you might need to load or define label_to_id here.\n",
        "# Example (if you saved label_to_id as a JSON file):\n",
        "# import json\n",
        "# with open(\"label_to_id.json\", \"r\") as f:\n",
        "#     label_to_id = json.load(f)\n",
        "# id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
        "\n",
        "# *** IMPORTANT ***\n",
        "# If you ran the training cell, label_to_id should be available in the environment.\n",
        "# If not, you need to recreate it based on your training data or load it.\n",
        "# Assuming label_to_id is available from a previous cell execution:\n",
        "try:\n",
        "    id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
        "    print(\"id_to_label mapping created from existing label_to_id.\")\n",
        "except NameError:\n",
        "    print(\"label_to_id not found. Please ensure the training cell was run or load label_to_id.\")\n",
        "    # As a fallback, you might attempt to infer labels from the model's config if available,\n",
        "    # but the most reliable way is to use the mapping from training.\n",
        "    id_to_label = {i: f\"LABEL_{i}\" for i in range(loaded_model.config.num_labels)}\n",
        "    print(f\"Using dummy id_to_label mapping: {id_to_label}\")\n",
        "\n",
        "\n",
        "def predict_intent(query):\n",
        "    \"\"\"\n",
        "    Predicts the intent of a given text query using the loaded model.\n",
        "\n",
        "    Args:\n",
        "        query (str): The input text query.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the predicted intent label (str) and the confidence score (float).\n",
        "    \"\"\"\n",
        "    # Tokenize the input text query\n",
        "    inputs = loaded_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Pass the tokenized input through the loaded model to get prediction scores\n",
        "    with torch.no_grad(): # Disable gradient calculation for inference\n",
        "        outputs = loaded_model(**inputs)\n",
        "\n",
        "    # Apply softmax to get probabilities and find the predicted class\n",
        "    probs = outputs.logits.softmax(dim=-1)\n",
        "    pred_id = probs.argmax().item()\n",
        "    confidence = probs.max().item()\n",
        "\n",
        "    # Map the predicted class index back to the original intent label string\n",
        "    # Ensure id_to_label is accessible (defined globally or passed)\n",
        "    try:\n",
        "        pred_label = id_to_label[pred_id]\n",
        "    except NameError:\n",
        "        print(\"Error: id_to_label mapping is not available. Cannot interpret prediction.\")\n",
        "        return f\"Unknown (ID: {pred_id})\", confidence\n",
        "    except KeyError:\n",
        "        print(f\"Error: Predicted ID {pred_id} not found in id_to_label mapping.\")\n",
        "        # Fallback if predicted ID is not in the mapping (shouldn't happen with correct setup)\n",
        "        return f\"Unknown (ID: {pred_id})\", confidence\n",
        "\n",
        "\n",
        "    return pred_label, confidence\n",
        "\n",
        "# Example usage\n",
        "query = \"what is the weather like today?\"\n",
        "intent, confidence = predict_intent(query)\n",
        "print(f\"Query: '{query}' -> Predicted Intent: '{intent}' (confidence: {confidence:.2f})\")\n",
        "\n",
        "query = \"tell me a joke\"\n",
        "intent, confidence = predict_intent(query)\n",
        "print(f\"Query: '{query}' -> Predicted Intent: '{intent}' (confidence: {confidence:.2f})\")\n",
        "\n",
        "query = \"set a timer for 5 minutes\"\n",
        "intent, confidence = predict_intent(query)\n",
        "print(f\"Query: '{query}' -> Predicted Intent: '{intent}' (confidence: {confidence:.2f})\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model and tokenizer loaded successfully.\n",
            "id_to_label mapping created from existing label_to_id.\n",
            "Query: 'what is the weather like today?' -> Predicted Intent: 'r' (confidence: 1.00)\n",
            "Query: 'tell me a joke' -> Predicted Intent: 'r' (confidence: 1.00)\n",
            "Query: 'set a timer for 5 minutes' -> Predicted Intent: 'r' (confidence: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eb86093",
        "outputId": "18cc212c-4834-4490-c15c-940a3ae35251"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path in Google Drive where you want to save the model\n",
        "save_path = \"/content/drive/MyDrive/trained_chatbot_model\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# To save the trained model and tokenizer to Google Drive\n",
        "print(f\"Saving trained model and tokenizer to: {save_path}\")\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(\"Model and tokenizer saved successfully.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving trained model and tokenizer to: /content/drive/MyDrive/trained_chatbot_model\n",
            "Model and tokenizer saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Set device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize wandb run with config for intent classification model\n",
        "config = {\n",
        "    \"epochs\": 5,\n",
        "    \"batch_size\": 128,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout\": random.uniform(0.01, 0.8),\n",
        "    \"architecture\": \"SimpleNN\",\n",
        "    \"dataset\": \"MNIST (as example)\",\n",
        "}\n",
        "project_name = \"ai_voice_chatbot_intent\"\n",
        "\n",
        "with wandb.init(project=project_name, config=config) as run:\n",
        "    config = run.config\n",
        "\n",
        "    # Prepare dataset and dataloaders (simulate intent classification with MNIST)\n",
        "    def get_dataloader(train, batch_size, slice_step=5):\n",
        "        dataset = MNIST(root=\".\", train=train, transform=T.ToTensor(), download=True)\n",
        "        subset = Subset(dataset, indices=range(0, len(dataset), slice_step))\n",
        "        loader = DataLoader(subset, batch_size=batch_size, shuffle=train, num_workers=2, pin_memory=True)\n",
        "        return loader\n",
        "\n",
        "    train_loader = get_dataloader(train=True, batch_size=config.batch_size)\n",
        "    val_loader = get_dataloader(train=False, batch_size=config.batch_size * 2)\n",
        "\n",
        "    # Define a simple feedforward model for classification (simulate intent classifier)\n",
        "    class IntentClassifier(nn.Module):\n",
        "        def __init__(self, dropout):\n",
        "            super().__init__()\n",
        "            self.model = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(28 * 28, 256),\n",
        "                nn.BatchNorm1d(256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(256, 10),  # 10 classes as example intents\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.model(x)\n",
        "\n",
        "    model = IntentClassifier(config.dropout).to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    # Validation function\n",
        "    def validate(model, loader, loss_fn):\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                val_loss += loss_fn(outputs, labels).item() * labels.size(0)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "        val_loss /= len(loader.dataset)\n",
        "        accuracy = correct / len(loader.dataset)\n",
        "        return val_loss, accuracy\n",
        "\n",
        "    # Training loop with wandb logging\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for step, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Log training loss every 50 steps\n",
        "            if step % 50 == 0:\n",
        "                wandb.log({\"train_loss\": loss.item(), \"epoch\": epoch + step / len(train_loader)})\n",
        "\n",
        "        val_loss, val_acc = validate(model, val_loader, loss_fn)\n",
        "        wandb.log({\"val_loss\": val_loss, \"val_accuracy\": val_acc, \"epoch\": epoch + 1})\n",
        "\n",
        "        # Save model checkpoint to wandb\n",
        "        checkpoint_path = f\"model_epoch_{epoch+1}.pt\"\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        run.log_artifact(checkpoint_path, type=\"model\", aliases=[f\"epoch-{epoch+1}\"])\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={running_loss/len(train_loader):.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "    # Finish wandb run\n",
        "    run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JYj5qbHPn39C",
        "outputId": "f7072b97-ad06-4618-b10b-572f16de470c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁</td></tr><tr><td>train/global_step</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>789326078976.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>3</td></tr><tr><td>train_loss</td><td>0.03913</td></tr><tr><td>train_runtime</td><td>39.845</td></tr><tr><td>train_samples_per_second</td><td>0.075</td></tr><tr><td>train_steps_per_second</td><td>0.075</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">blooming-paper-2</strong> at: <a href='https://wandb.ai/dushyant3615-own/huggingface/runs/zwm8wuhw' target=\"_blank\">https://wandb.ai/dushyant3615-own/huggingface/runs/zwm8wuhw</a><br> View project at: <a href='https://wandb.ai/dushyant3615-own/huggingface' target=\"_blank\">https://wandb.ai/dushyant3615-own/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250831_213908-zwm8wuhw/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250901_001357-ku8py14i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent/runs/ku8py14i' target=\"_blank\">super-sound-1</a></strong> to <a href='https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent' target=\"_blank\">https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent/runs/ku8py14i' target=\"_blank\">https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent/runs/ku8py14i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 25.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.00MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 8.16MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.24MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=0.5965, Val Loss=0.3094, Val Acc=0.9120\n",
            "Epoch 2: Train Loss=0.2932, Val Loss=0.2507, Val Acc=0.9230\n",
            "Epoch 3: Train Loss=0.2285, Val Loss=0.2241, Val Acc=0.9260\n",
            "Epoch 4: Train Loss=0.1990, Val Loss=0.2071, Val Acc=0.9390\n",
            "Epoch 5: Train Loss=0.1737, Val Loss=0.1928, Val Acc=0.9395\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▂▃▄▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅██</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>train_loss</td><td>0.16762</td></tr><tr><td>val_accuracy</td><td>0.9395</td></tr><tr><td>val_loss</td><td>0.19278</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">super-sound-1</strong> at: <a href='https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent/runs/ku8py14i' target=\"_blank\">https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent/runs/ku8py14i</a><br> View project at: <a href='https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent' target=\"_blank\">https://wandb.ai/dushyant3615-own/ai_voice_chatbot_intent</a><br>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250901_001357-ku8py14i/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b82446ef",
        "outputId": "7fafd376-86e9-42e4-fd6b-9e7c196175ef"
      },
      "source": [
        "pip -q install evaluate"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81.9/84.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}