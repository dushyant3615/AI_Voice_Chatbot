{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dushyant3615/AI_Voice_Chatbot/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip -q install torch transformers datasets pandas speechrecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuQeQYRMf6kr",
        "outputId": "1b218c0a-e88e-4df6-93ce-1af163a2467e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip -q install pydub"
      ],
      "metadata": {
        "id": "n1GBqZ9ntgrA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3klY8Q49YqS",
        "outputId": "19d48f0b-2ce5-4389-f90a-9fca656a3c75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "def load_clinc_data(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Extract user queries and intents\n",
        "    queries = [item[0] for item in data]  # User query\n",
        "    intents = [item[1] for item in data]  # Intent\n",
        "\n",
        "    return pd.DataFrame({\"query\": queries, \"intent\": intents})\n",
        "\n",
        "# To load the Clinc AI dataset\n",
        "clinc_data = load_clinc_data(\"/content/drive/MyDrive/AI_voice_chatbot/Clinc_AI_Dataset/train.json\")\n",
        "\n",
        "def load_mozilla_data(csv_path, audio_folder):\n",
        "    df = pd.read_csv(csv_path, sep=\"\\t\")  # Use tab separator for TSV files\n",
        "\n",
        "    # To extract sentences and corresponding audio file paths\n",
        "    sentences = df['sentence'].tolist()\n",
        "    audio_files = [os.path.join(audio_folder, row['path']) for _, row in df.iterrows()]\n",
        "\n",
        "    return pd.DataFrame({\"sentence\": sentences, \"audio_path\": audio_files})\n",
        "\n",
        "# To load the Mozilla Common Voice dataset\n",
        "# Assuming the Mozilla Common Voice dataset is also in your Google Drive\n",
        "mozilla_data = load_mozilla_data(\"/content/drive/MyDrive/AI_voice_chatbot/Mozilla_Common_Voice_Dataset/cv-corpus-20.0-delta-2024-12-06/en/validated.tsv\",\n",
        "                                 \"/content/drive/MyDrive/AI_voice_chatbot/Mozilla_Common_Voice_Dataset/cv-corpus-20.0-delta-2024-12-06/en/clips\")\n",
        "\n",
        "def audio_to_text(audio_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(audio_path):\n",
        "        print(f\"File not found: {audio_path}\")\n",
        "        return \"\"  # To return empty string if file is missing\n",
        "\n",
        "    # Convert MP3 to WAV if the file is not already in WAV format\n",
        "    if audio_path.endswith(\".mp3\"):\n",
        "        try:\n",
        "            audio = AudioSegment.from_mp3(audio_path)\n",
        "            wav_path = audio_path.replace(\".mp3\", \".wav\")\n",
        "            audio.export(wav_path, format=\"wav\")\n",
        "            audio_path = wav_path  # To use the converted WAV file\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting {audio_path} to WAV: {e}\")\n",
        "            return \"\"  # To return empty string if conversion fails\n",
        "\n",
        "    try:\n",
        "        with sr.AudioFile(audio_path) as source:\n",
        "            audio = recognizer.record(source)\n",
        "            return recognizer.recognize_google(audio)  # To convert the speech to text\n",
        "    except sr.UnknownValueError:\n",
        "        print(f\"Could not transcribe audio: {audio_path}\")\n",
        "        return \"\"  # If audio cannot be transcribed\n",
        "    except sr.RequestError:\n",
        "        print(f\"API error for audio: {audio_path}\")\n",
        "        return \"\"  # If there's an API error\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error for audio: {audio_path}: {e}\")\n",
        "        return \"\"  # Handle any other errors\n",
        "\n",
        "# Filter out rows where audio files are missing before transcription\n",
        "mozilla_data = mozilla_data[mozilla_data[\"audio_path\"].apply(os.path.exists)].copy()\n",
        "\n",
        "\n",
        "# To transcribe audio files to text\n",
        "mozilla_data[\"transcribed_text\"] = mozilla_data[\"audio_path\"].apply(audio_to_text)\n",
        "\n",
        "# To combine the datasets\n",
        "combined_data = pd.concat([\n",
        "    clinc_data.rename(columns={\"query\": \"text\", \"intent\": \"label\"}),\n",
        "    mozilla_data.rename(columns={\"transcribed_text\": \"text\"})[[\"text\"]]\n",
        "], ignore_index=True)\n",
        "\n",
        "# To add dummy labels for Mozilla data (since it doesn't have intents)\n",
        "combined_data[\"label\"] = combined_data[\"label\"].fillna(\"unknown\")\n",
        "\n",
        "# To convert labels to numerical values\n",
        "label_to_id = {label: idx for idx, label in enumerate(combined_data[\"label\"].unique())}\n",
        "combined_data[\"label\"] = combined_data[\"label\"].map(label_to_id)\n",
        "\n",
        "# To load pre-trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# To tokenize the text data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# To convert DataFrame to Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(combined_data)\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# To load pre-trained BERT model for intent classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_to_id))\n",
        "\n",
        "# To define training settings\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",  # Directory to save results\n",
        "    per_device_train_batch_size=8,  # Batch size for training\n",
        "    num_train_epochs=3,  # Number of training epochs\n",
        "    logging_dir=\"./logs\",  # Directory to save logs\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ") # To initialize Trainer\n",
        "\n",
        "trainer.train() # To train the model\n",
        "\n",
        "model.save_pretrained(\"trained_chatbot_model\") # To save the trained model\n",
        "tokenizer.save_pretrained(\"trained_chatbot_model\")\n",
        "\n",
        "print(\"Model Training Complete. Chatbot is Ready!\")"
      ],
      "metadata": {
        "id": "sWHCFloalYgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XMOoFZ4c_v17"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}